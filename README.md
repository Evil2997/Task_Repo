# Court Registry Loader (Ukraine) — 2025

Инструмент для авто-загрузки реестра стану розгляду справ, извлечения CSV из архивов и импорта данных в **SQLite** с
учётом кодировок, дедупликации и нормализации.

## Задание (формулировка)

* Источник: офиц. страница реестра; данные опубликованы архивами с CSV за 2019–2025 гг. (важно учитывать кодировку)
  .&#x20;
* Цель: реализовать **автоматическую загрузку всех CSV за 2025 год**.&#x20;
* Процесс: скачать архив → импортировать в **SQLite** → **после успешного импорта удалить архив**.&#x20;
* Типы данных подбирать по смыслу колонок; база **не должна содержать полных дублей**; по возможности — **нормализация**
  .&#x20;
* Бонус: выгрузка из БД по списку номеров дел из входного CSV (одна колонка).&#x20;
* Репозиторий: код + `requirements.txt` и **README** с описанием алгоритма.&#x20;

---

## Что делает проект

1. **Проверяет и докачивает архивы** за выбранный год (по умолчанию — 2025), пропуская уже имеющиеся локально.
2. **Распаковывает ZIP** во временную папку.
3. **Читает все CSV** с авто-выбором кодировки (`utf-8-sig`, `cp1251`, …) как **строки** (без NA), корректно обрабатывая
   пустые значения.
4. **Импортирует в SQLite** по нормализованной схеме, **без дублей** (через `UNIQUE`/UPSERT).
5. При **успехе** импорта архива — **удаляет ZIP**.

---

## Нормализованная схема БД

Происходит разнесение исходных 13 CSV-полей по четырём таблицам:

### `cases` — дела

* `id` INTEGER PK
* `court_name` TEXT
* `case_number` TEXT
* `registration_date` DATE (`YYYY-MM-DD`)
* `type` TEXT
* `description` TEXT
  **UNIQUE(court\_name, case\_number)**

### `judges` — судьи (справочник)

* `id` INTEGER PK
* `name` TEXT UNIQUE

### `case_judges` — связь дело↔судья

* `id` INTEGER PK
* `case_id` FK → cases.id
* `judge_id` FK → judges.id
* `role` TEXT
  **UNIQUE(case\_id, judge\_id, role)**

### `case_events` — стадии/результаты

* `id` INTEGER PK
* `case_id` FK → cases.id
* `case_proc` TEXT
* `stage_date` TEXT (`YYYY-MM-DD`)
* `stage_name` TEXT
* `cause_result` TEXT
* `cause_dep` TEXT
  **UNIQUE(case\_id, stage\_date, stage\_name, cause\_result, cause\_dep)**

---

## Установка

```bash
    python3.13 -m venv .venv
    source .venv/bin/activate   # Windows: .venv\Scripts\activate
    pip install -r requirements.txt
```

---

## Запуск (импорт 2025)

```bash
    python main.py
    # или с указанием года:
    # python main.py --year 2025
```

Что произойдёт:

* проверка локальных ZIP за год → догрузка недостающих;
* распаковка;
* импорт всех CSV в БД;
* успешный архив удаляется.

Пути (можно править в `paths.py`/`config.py`):

* входные ZIP: `INPUT_DIR`
* выходная БД: `DB_PATH` (по умолчанию `output_dir/court_registry.db`)

---

## Алгоритмические детали

* **Кодировки CSV**: пробуем `utf-8-sig`, `cp1251`, `windows-1251`, `utf-8`.
* **Чтение только строками**: `dtype=str, keep_default_na=False, na_filter=False` — так пустые ячейки не превращаются в
  `NaN`, и строковые операции безопасны.
* **Даты**: вход `DD.MM.YYYY` → хранение `YYYY-MM-DD`. Пустые — `""` (для участия в `UNIQUE`).
* **Парсинг судей**: строки вида `«роль: ПІБ»`, множ. значения разделены `;`.
* **Дедуп**: `UNIQUE` на ключевых комбинациях (дело, связка дело↔судья, событие).
* **Надёжность**: импорт транзакционно; архив удаляется только после полного успеха его CSV.

---

## Лицензия

MIT.

---
